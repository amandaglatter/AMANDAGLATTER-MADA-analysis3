---
title: "analysis3week9"
output: html_document
---
This file uses processed_data file.

#Load libraries
```{r}
library(tidyverse)
library(dplyr)
library(broom)
library(ggplot2)
library(rsample) #for training and testing
library(tidymodels) #for modeling and recipes
```

#Locate file and download data
```{r}
data_location <- here::here("data","processed_data","processed_data.rds")
dat <- readRDS(data_location)
```


"Write code that takes the data and splits it randomly into a _train and test_ that, following for instance the example in the Data Splitting section of the Get Started tidymodels tutorial."
* Training set is used to fit the model
* Testing set is used for evaluation
* Use rsample package ot create an object that tells how to split the data
* use rsample to then create dataframes for training and testing sets

```{r}
#Fic the random numbers by setting the seed, allowing the analysis to be reproducible when random numbers are used.
#We can pick any random number (?)
set.seed(48)

#Put 3/4 data into the training set
data_split <- initial_split(dat, prop =3/4)

#Create data frames for the two sets:
train_data <- training(data_split)
test_data <- testing(data_split)

```

Congratulations! We have created our training and testing data sets.

We are focusing on our _categorical outcome of interest_, which was _nausea_.We are fitting this outcome to all predictors, starting with categorical.

_Creating a Recipe._
A recipe is a description of the steps to be applied to a data set in order to prepare it for analysis.
https://recipes.tidymodels.org/reference/recipe.html
```{r}
data_recipe <- recipe(Nausea ~ ., data = train_data) #First part is the formula: Nausea is the outcome of interest and to the right of tilde are predictors (a period indicates all other variables). Second part is the data used in the model (usually training set)

```

Set a model. Set a logistical model to a categorical outcome.
```{r}
log_mod <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

```

Now we want to process the recipe using the training set, apply the recipe to the training set, and apply the recipe to the test set. To simplify the process, we use _workflows package_ from tinymodels.

```{r}
nausea_wflow <- workflow() %>%
  add_model(log_mod) %>%
  add_recipe(data_recipe)

nausea_wflow
```
In a single fucntion, we can prepare the recipe and train the model from the resulting predictors:
```{r}
nausea_fit <- nausea_wflow %>%
  fit(data=dat)

#the following extracts the finalized recipe and fitted model objects inside.
nausea_fit %>% extract_fit_parsnip() %>%
  tidy()


```

Now we are using the trained workflow to predict with the unseen test data. For this, we use the single call "predict()".

```{r}
predict(nausea_fit, test_data)

```
The output from predict() returns Yes or No. To get back predicted class probabilities, we can specify "type = "prob"" when we use predict() or augment().
```{r}
nausea_aug <- augment(nausea_fit, dat)
#This produces a tibble with predicted class probabilities.
```
Now we use the area under the ROC curve as our metric, computed using roc_curve() and roc_auc() from yardstick package.
ROC helps determine what probability cutoff should be used.Commonly, the area under the ROC curve (AUC) is used to evaluate models. If the best model immediately proceeds to the upper left corner, the area under this curve would be one while the poor model would produce an AUC in the neighborhood of 0.50. 

```{r}
nausea_aug %>% roc_curve(truth = Nausea, .pred_Yes) %>% autoplot()
```

This is pretty low and indicates it may not be useful.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Letâ€™s re-do the fitting but now with a model that only fits the main predictor to the categorical outcome.

```{r}
data_recipe_nose <- recipe(Nausea ~ RunnyNose, data = train_data) 
```

Set a model again. Set a logistical model to a categorical outcome.

```{r}
log_mod_nose <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

```

Now we want to process the recipe using the training set, apply the recipe to the training set, and apply the recipe to the test set. To simplify the process, we use _workflows package_ from tinymodels.

```{r}
nausea_nose_wflow <- workflow() %>%
  add_model(log_mod_nose) %>%
  add_recipe(data_recipe_nose)

nausea_nose_wflow
```

In a single function, we can prepare the recipe and train the model from the resulting predictors:
```{r}
nausea_nose_fit <- nausea_nose_wflow %>%
  fit(data=dat)

#the following extracts the finalized recipe and fitted model objects inside.
nausea_nose_fit %>% extract_fit_parsnip() %>%
  tidy()


```

Now we are using the trained workflow to predict with the unseen test data. For this, we use the single call "predict()".

```{r}
predict(nausea_nose_fit, test_data)

```
The output from predict() returns Yes or No. To get back predicted class probabilities, we can specify "type = "prob"" when we use predict() or augment().
```{r}
nausea_nose_aug <- augment(nausea_nose_fit, dat)
#This produces a tibble with predicted class probabilities.
```
Now we use the area under the ROC curve as our metric, computed using roc_curve() and roc_auc() from yardstick package.
ROC helps determine what probability cutoff should be used.Commonly, the area under the ROC curve (AUC) is used to evaluate models. If the best model immediately proceeds to the upper left corner, the area under this curve would be one while the poor model would produce an AUC in the neighborhood of 0.50. 

```{r}
nausea_nose_aug %>% roc_curve(truth = Nausea, .pred_Yes) %>% autoplot()
```



This is almost perfectly 0.5. This means the model is no good.





####Nicholas' Code Starts Here

```{r}
# Creates a simple recipe that fits our continuous outcome of interest to all predictors 
bodytmp_rec <- 
  recipe(BodyTemp ~ ., data = train_data)

# Set a model as we did in the previous exercise
lr_mod <- 
  linear_reg() %>% 
  set_engine("lm")


# Use the workflow() package to create a
# simple workflow that fits a linear model
# to all predictors using the glm function
bodytmp_wflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(bodytmp_rec)

# Fitting the model
bodytmp_fit <- 
  bodytmp_wflow %>% 
  fit(data = train_data)

# Extracting Model/Recipes with Parsnip
bodytmp_fit %>% 
  extract_fit_parsnip() %>% 
  tidy()
```



```{r}

# Obtaining Predictions
predict(bodytmp_fit, train_data)

bodytmp_aug <- 
  augment(bodytmp_fit, train_data)

bodytmp_aug %>%
  select(BodyTemp)


```

##Calculating RMSE on for Complex Model on Training Data
```{r}
# Calculating Root RMSE 
rmse_train <- bodytmp_aug %>% 
  rmse(truth = BodyTemp, .pred)

rmse_train
```


```{r}

# Now on Test Data


# Obtaining Predictions
predict(bodytmp_fit, test_data)

bodytmp_aug <- 
  augment(bodytmp_fit, test_data)

bodytmp_aug %>%
  select(BodyTemp)

```



##Calculating RMSE for Complex Model on Test Data
```{r}
# Calculating Root RMSE 
rmse_test <- bodytmp_aug %>% 
  rmse(truth = BodyTemp, .pred)

rmse_test 

```


###NOW WITH ONLY ONE PREDICTOR

```{r}

# Creates a simple recipe that fits our categorical outcome of interest to all predictors 
bodytmp_runny_rec <- 
  recipe(BodyTemp ~ RunnyNose, data = train_data) 


# Set a model as we did in the previous exercise
lr_mod <- 
  linear_reg() %>% 
  set_engine("lm")


# Use the workflow() package to create a
# simple workflow that fits a linear model
# to all predictors using the glm function
bodytmp_runny_wflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(bodytmp_runny_rec)

# Fitting the model
bodytmp_runny_fit <- 
  bodytmp_runny_wflow %>% 
  fit(data = train_data)

# Extracting Model/Recipes with Parsnip
bodytmp_runny_fit %>% 
  extract_fit_parsnip() %>% 
  tidy()

```


```{r}
# For Training Data

# Obtaining Predictions
predict(bodytmp_runny_fit, train_data)

bodytmp_runny_aug <- 
  augment(bodytmp_runny_fit, train_data)

bodytmp_runny_aug %>%
  select(BodyTemp)

```


##Calculating RMSE for Simple Model from Training Data
```{r}
# Calculating Root RMSE 
rmse_runny_train <- bodytmp_runny_aug %>% 
  rmse(truth = BodyTemp, .pred)

rmse_runny_train
```

```{r}

# For Test Data

# Obtaining Predictions
predict(bodytmp_runny_fit, test_data)

bodytmp_runny_aug <- 
  augment(bodytmp_runny_fit, test_data)

bodytmp_runny_aug %>%
  select(BodyTemp)
```


##Calculating RMSE for Simple Model from Test Data
```{r}

# Calculating Root RMSE 
rmse_runny_test <- bodytmp_runny_aug %>% 
  rmse(truth = BodyTemp, .pred)

rmse_runny_test

```


###Conclusion




